{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325b4f3b-f726-4d07-8992-2c28442f3e14",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "**Comparing Federated Machine Learning to Centralized Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f3a2e",
   "metadata": {},
   "source": [
    "## Imports & Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461e8e2d-cc30-45cf-bec2-c45763034af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d408b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 1.0 / Number of CPU Cores: 24\n",
      "Training on NVIDIA GeForce RTX 4090\n",
      "Flower 1.14.0 / PyTorch 2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    n_gpu = float(torch.cuda.device_count())\n",
    "    device_name = torch.cuda.get_device_name(DEVICE)\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    device_name = \"Apple Silicon\"\n",
    "    n_gpu = 0.0\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    device_name = \"CPU\"\n",
    "    n_gpu = 0.0\n",
    "    \n",
    "disable_progress_bar()\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Number of GPUs: {n_gpu} / Number of CPU Cores: {n_cores}\")\n",
    "print(f\"Training on {device_name}\")\n",
    "print(f\"Flower {fl.__version__} / PyTorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b8b85d-b71e-4b9a-8de6-f89b9f36e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 5\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 8\n",
    "NUM_ROUNDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f82c6-0bb0-4db3-8e94-2fa98159144f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a7e93b-f8c6-42b3-9bf6-8a1717ba4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./Data/adult_train.csv')\n",
    "test_df = pd.read_csv('./Data/adult_train.csv')\n",
    "concated_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "label_column_name = 'income'\n",
    "x_train = train_df.drop(columns=[label_column_name]).values\n",
    "x_test = test_df.drop(columns=[label_column_name]).values\n",
    "y_train = train_df[label_column_name].values\n",
    "y_test = test_df[label_column_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3a95b4-e964-4d41-abdd-fe728b146c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be931bb7-d190-4ed4-9be9-4c7edb899ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(features, labels, num_clients):\n",
    "    dataset = CustomDataset(features, labels)\n",
    "    dataset_size = len(dataset)\n",
    "    partition_size = dataset_size // num_clients\n",
    "    \n",
    "    lengths = [partition_size] * num_clients\n",
    "    lengths[-1] += dataset_size % num_clients\n",
    "    partitions = random_split(dataset, lengths)\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1eb5cde-ce3b-4e32-8d24-8d59ca314cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_federated_datasets(x_train, x_test, y_train, y_test, num_clients, batch_size):\n",
    "    train_partitions = partition_dataset(x_train, y_train, num_clients)\n",
    "    test_partitions = partition_dataset(x_test, y_test, num_clients)\n",
    "    \n",
    "    federated_trainloaders = []\n",
    "    federated_testloaders = []\n",
    "\n",
    "    for train_partition, test_partition in zip(train_partitions, test_partitions):\n",
    "        trainloader = DataLoader(train_partition, batch_size=batch_size, shuffle=True)\n",
    "        testloader = DataLoader(test_partition, batch_size=batch_size, shuffle=False)\n",
    "        federated_trainloaders.append(trainloader)\n",
    "        federated_testloaders.append(testloader)\n",
    "\n",
    "    return federated_trainloaders, federated_testloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804581b6-e080-4cad-ace4-3b6324eb31fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ced28f-6869-4b40-8fae-cd90f26d1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binary_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Binary_MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(97, 64),            \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),              \n",
    "            nn.BatchNorm1d(64),            \n",
    "            \n",
    "            nn.Linear(64, 32),             \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            \n",
    "            nn.Linear(32, 16),             \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(16, 1)               \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba540a1-97ef-44fc-9a7c-1a05fbfc6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Assuming binary classification with logits output\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()  # Ensure labels are floats for BCELoss\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss for the batch\n",
    "            batch_loss = criterion(outputs, labels.unsqueeze(1))  # Labels reshaped for compatibility\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "            # Convert logits to predictions\n",
    "            preds = torch.sigmoid(outputs).round()  # Threshold at 0.5 for binary classification\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=1)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Average loss over all batches\n",
    "    avg_loss = total_loss / len(testloader)\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d4221-d565-4d97-ae96-d7883be3e870",
   "metadata": {},
   "source": [
    "## Centralized Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d987cc1c-6619-4ada-b6be-cd0389415586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_centralized = CustomDataset(x_train, y_train)\n",
    "test_centralized = CustomDataset(x_test, y_test)\n",
    "train_centralized_loader = DataLoader(train_centralized, batch_size=32, shuffle=True)\n",
    "test_centralized_loader = DataLoader(test_centralized, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "847059fb-7733-412c-bc99-6040a6da165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralized_training(model, loader, criterion, optimizer, num_epochs=NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(DEVICE).float()\n",
    "            labels = labels.to(DEVICE).float().unsqueeze(1)  # Ensure correct shape\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate predictions and update accuracy metrics\n",
    "            preds = torch.sigmoid(outputs).round()  # Threshold at 0.5 for binary classification\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    avg_loss = total_loss / (num_epochs * len(loader))  # Average loss over all batches\n",
    "    overall_accuracy = correct_predictions / total_samples\n",
    "    return overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0d9ede4-898e-42e1-87c0-daac681fe718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455475876048033"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Binary_MLP().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "centralized_training(model, train_centralized_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8a359bc-b1c8-4712-ba25-2b302864ac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralized Model - Average Loss: 0.3060, Accuracy: 0.8608, Precision: 0.7657, Recall: 0.6080, F1: 0.6778\n"
     ]
    }
   ],
   "source": [
    "c_loss, c_accuracy, c_precision, c_recall, c_f1 = evaluate_model(model, test_centralized_loader, DEVICE)\n",
    "\n",
    "print(f\"Centralized Model - Average Loss: {c_loss:.4f}, Accuracy: {c_accuracy:.4f}, Precision: {c_precision:.4f}, Recall: {c_recall:.4f}, F1: {c_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1a6755-b497-421f-9237-8d2adc8157d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.weight \t torch.Size([64, 97])\n",
      "model.0.bias \t torch.Size([64])\n",
      "model.3.weight \t torch.Size([64])\n",
      "model.3.bias \t torch.Size([64])\n",
      "model.3.running_mean \t torch.Size([64])\n",
      "model.3.running_var \t torch.Size([64])\n",
      "model.3.num_batches_tracked \t torch.Size([])\n",
      "model.4.weight \t torch.Size([32, 64])\n",
      "model.4.bias \t torch.Size([32])\n",
      "model.7.weight \t torch.Size([32])\n",
      "model.7.bias \t torch.Size([32])\n",
      "model.7.running_mean \t torch.Size([32])\n",
      "model.7.running_var \t torch.Size([32])\n",
      "model.7.num_batches_tracked \t torch.Size([])\n",
      "model.8.weight \t torch.Size([16, 32])\n",
      "model.8.bias \t torch.Size([16])\n",
      "model.11.weight \t torch.Size([1, 16])\n",
      "model.11.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936620d1-5d18-4c7f-b7c7-3f20ab04fe1c",
   "metadata": {},
   "source": [
    "## Federated Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae044a56-866d-4ad4-8da4-f5df131f92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_config = {\n",
    "    \"client_resources\": {\n",
    "        \"num_cpus\": n_cores,\n",
    "        \"num_gpus\": n_gpu\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a97a55e-0636-4cdd-9007-c8ef6cc122a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(model, parameters):\n",
    "    params_dict = zip(model.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "def get_parameters(model) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ea88c69-fe7d-4421-9de1-74f5a7d1f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, model, trainloader, testloader):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.model)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.model, parameters)\n",
    "        accuracy = centralized_training(self.model, self.trainloader, criterion, optimizer)\n",
    "        return get_parameters(self.model), len(self.trainloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy, precision, recall, f1 = evaluate_model(self.model, self.testloader, DEVICE)\n",
    "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "767d35e0-6607-4e15-808b-7e189ce266a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    model = Binary_MLP().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "\n",
    "    trainloaders, testloaders = load_federated_datasets(\n",
    "        x_train,\n",
    "        x_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        NUM_CLIENTS,\n",
    "        BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    trainloader = trainloaders[partition_id]\n",
    "    testloader = testloaders[partition_id]\n",
    "\n",
    "    return FlowerClient(model, trainloader, testloader).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "113c4310-6789-4ca6-9288-93b8568bf1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "242ce0d3-6fd7-42ac-9c69-b3517acb8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=1.0, \n",
    "        fraction_evaluate=0.5,\n",
    "        min_available_clients=NUM_CLIENTS, \n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        fit_metrics_aggregation_fn=weighted_average\n",
    "    )\n",
    "    config = ServerConfig(num_rounds=NUM_ROUNDS)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e5839-aee4-4f23-a573-8362fe35d003",
   "metadata": {},
   "source": [
    "### Federated with 5 Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92c43d2b-519e-4c6d-b5b3-ca6fe85a8748",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "client_fn() missing 1 required positional argument: 'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m ClientApp(client_fn\u001b[38;5;241m=\u001b[39m\u001b[43mclient_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestloaders\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m server \u001b[38;5;241m=\u001b[39m ServerApp(server_fn\u001b[38;5;241m=\u001b[39mserver_fn)\n\u001b[1;32m      4\u001b[0m run_simulation(\n\u001b[1;32m      5\u001b[0m     server_app\u001b[38;5;241m=\u001b[39mserver,\n\u001b[1;32m      6\u001b[0m     client_app\u001b[38;5;241m=\u001b[39mclient,\n\u001b[1;32m      7\u001b[0m     num_supernodes\u001b[38;5;241m=\u001b[39mNUM_CLIENTS,\n\u001b[1;32m      8\u001b[0m     backend_config\u001b[38;5;241m=\u001b[39mbackend_config,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: client_fn() missing 1 required positional argument: 'context'"
     ]
    }
   ],
   "source": [
    "client = ClientApp(client_fn=client_fn)\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa9005e-5bb7-4a4d-8f06-d38d242469c1",
   "metadata": {},
   "source": [
    "### Federated with 50 Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13139d1b-bc39-48db-8285-9ed562bab921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=15, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 25 clients (out of 50)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 25 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 15 round(s) in 245.42s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6778611473810106\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6786933885301862\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.6789460578418913\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.6783796115148635\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.6786689449491955\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.6793478637649899\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.6775619120824905\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.6790142657643273\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.6783855290639969\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.6789635269982475\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.6785180080504645\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.6784850632576716\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 13: 0.6782605006581262\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 14: 0.6789084435644603\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 15: 0.678926838579632\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.5737907228479541),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.5754415180456746),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.5750361110724378),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.5734205800047336),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.5752268471466162),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.5756454339361706),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.5755988405010186),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.5717429784992645),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.5759429833720838),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.5722972733094797),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.5742361159452574),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.5734726727646521),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.5730031302063755),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.5716431321090953),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.5720734078642665)]}\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.6349001536098311),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.6334254992319509),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.6339869408439724),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.6350582185900379),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.6360074438117513),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.6344211322576003),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.6401843317972351),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.6314592933947771),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.6362050482409123),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.6313274952315981),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.6385253456221196),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.6388840779465473),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.6372350230414747),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.635581420171616),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.6352073732718895)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 50\n",
    "\n",
    "client = ClientApp(client_fn=client_fn)\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714024a-ddd7-4ab4-8dad-9678ec4ebe59",
   "metadata": {},
   "source": [
    "### Federated with 200 Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e5771c3-ba19-4144-b037-dd26cb78369e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=15, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 200 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 200 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 100 clients (out of 200)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 100 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 15 round(s) in 428.87s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.768543817003568\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.7691964164253109\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.7671280811640842\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.770842880209287\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.7700320034972893\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.7689933842917284\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.7682584127611365\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.7682307349748848\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.7715433540940285\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.769022127616504\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.7726772409825285\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.7674016187506274\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 13: 0.7718077676355346\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 14: 0.7695795731111006\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 15: 0.7667416551709175\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.2824426754516809),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.28263133867266543),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.28015897145298635),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.2812842540136581),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.28103045493755013),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.28332704099086436),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.2879331308364748),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.2830711365374083),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.28961532733740886),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.2835930798030795),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.2841528247027135),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.2827269013936408),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.28330982923367615),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.28416844255840695),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.2837369591499698)]}\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.24302469135802482),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.25623473689896425),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.24716249652922873),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.2537037037037036),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.2566759631212206),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.25660493827160485),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.25027969913981735),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.2531668121310677),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.2517283950617282),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.25505964988092755),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.2499736079246351),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.2491876263337001),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.24810048131185206),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.2516412838394262),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.25345679012345673)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 200\n",
    "\n",
    "client = ClientApp(client_fn=client_fn)\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a649d9f-ba12-4e4e-a9be-dc5d3e5fead1",
   "metadata": {},
   "source": [
    "### Dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ab8df-d7da-4dcc-82a4-f110cfcacb45",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40616b8e-ac34-423b-ba70-ad530e21b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset_by_binary_attribute(features, labels, binary_column, source_df, num_clients):\n",
    "    \"\"\"\n",
    "    Partition the dataset such that some clients are dominated by one binary attribute value.\n",
    "\n",
    "    Args:\n",
    "    - features: The feature matrix.\n",
    "    - labels: The label vector.\n",
    "    - binary_column: Column with binary values (e.g., 'sex_Male').\n",
    "    - source_df: The dataframe corresponding to features and labels (e.g., train_df or test_df).\n",
    "    - num_clients: Total number of clients.\n",
    "\n",
    "    Returns:\n",
    "    - partitions: List of partitioned datasets for clients.\n",
    "    \"\"\"\n",
    "    # Separate the dataset by binary attribute\n",
    "    male_indices = source_df[binary_column] == 1.0\n",
    "    female_indices = source_df[binary_column] == 0.0\n",
    "    \n",
    "    male_features = features[male_indices]\n",
    "    male_labels = labels[male_indices]\n",
    "    \n",
    "    female_features = features[female_indices]\n",
    "    female_labels = labels[female_indices]\n",
    "\n",
    "    # Number of clients per group\n",
    "    clients_per_group = num_clients // 2\n",
    "\n",
    "    # Partition each group\n",
    "    male_partitions = partition_dataset(male_features, male_labels, clients_per_group)\n",
    "    female_partitions = partition_dataset(female_features, female_labels, clients_per_group)\n",
    "    \n",
    "    partitions = male_partitions + female_partitions\n",
    "\n",
    "    # Handle any leftover clients\n",
    "    remaining_clients = num_clients % 2\n",
    "    if remaining_clients > 0:\n",
    "        remaining_indices = source_df.sample(n=remaining_clients, random_state=42).index\n",
    "        remaining_features = features[remaining_indices]\n",
    "        remaining_labels = labels[remaining_indices]\n",
    "        remaining_partitions = partition_dataset(remaining_features, remaining_labels, remaining_clients)\n",
    "        partitions.extend(remaining_partitions)\n",
    "\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def load_federated_datasets_by_binary_attribute(\n",
    "    x_train, x_test, y_train, y_test, train_df, test_df, num_clients, batch_size, binary_column\n",
    "):\n",
    "    \"\"\"\n",
    "    Load federated train and test datasets partitioned by a binary attribute.\n",
    "\n",
    "    Args:\n",
    "    - x_train, x_test, y_train, y_test: Training and testing features and labels.\n",
    "    - train_df, test_df: Source dataframes corresponding to the features and labels.\n",
    "    - num_clients: Total number of clients.\n",
    "    - batch_size: Batch size for each client.\n",
    "    - binary_column: Column name with binary values (e.g., 'sex_Male').\n",
    "\n",
    "    Returns:\n",
    "    - federated_trainloaders: List of DataLoaders for training.\n",
    "    - federated_testloaders: List of DataLoaders for testing.\n",
    "    \"\"\"\n",
    "    train_partitions = partition_dataset_by_binary_attribute(\n",
    "        x_train, y_train, binary_column, train_df, num_clients\n",
    "    )\n",
    "    test_partitions = partition_dataset_by_binary_attribute(\n",
    "        x_test, y_test, binary_column, test_df, num_clients\n",
    "    )\n",
    "    \n",
    "    federated_trainloaders = [\n",
    "        DataLoader(partition, batch_size=batch_size, shuffle=True) for partition in train_partitions\n",
    "    ]\n",
    "    federated_testloaders = [\n",
    "        DataLoader(partition, batch_size=batch_size, shuffle=False) for partition in test_partitions\n",
    "    ]\n",
    "\n",
    "    return federated_trainloaders, federated_testloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8fc369d-7bcd-46c3-b85d-c72688e9fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn_binary(context: Context) -> Client:\n",
    "    model = Binary_MLP().to(DEVICE)\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "\n",
    "    trainloaders, testloaders = load_federated_datasets_by_binary_attribute(\n",
    "        x_train,\n",
    "        x_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        train_df,\n",
    "        test_df,\n",
    "        NUM_CLIENTS,\n",
    "        BATCH_SIZE,\n",
    "        'sex_Male'\n",
    "    )\n",
    "\n",
    "    trainloader = trainloaders[partition_id]\n",
    "    testloader = testloaders[partition_id]\n",
    "\n",
    "    return FlowerClient(model, trainloader, testloader).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddb52f4b-706a-4117-832b-63635506d457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=15, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 15 round(s) in 212.58s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6356974739160498\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.6356585928585738\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.6480229717570466\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.6335108598156454\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.6378149882769485\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.6440054991127586\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.6358369370634087\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.629068911075592\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.6363637439875424\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.6432444431446153\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.6373125700022885\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.6422930783719859\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 13: 0.6374926639401264\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 14: 0.6262155409838576\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 15: 0.6367063259230498\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.7262161506146071),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.7268774331427249),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.725011710189124),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.7258046834325632),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.7246830121731748),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.7241323957040312),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.725844433271914),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.728548971057109),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.7255425750393446),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.7245079273751032),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.7239382972420099),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.7256578813985336),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.722487391195109),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.7235050911283051),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.7243654267009171)]}\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.7823799566332348),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (2, 0.7794749848219624),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (3, 0.7207472487907088),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (4, 0.7831036094478543),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (5, 0.7796222364737824),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (6, 0.740115998975675),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (7, 0.7782376375406613),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (8, 0.8202802501902202),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (9, 0.7810029005934476),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (10, 0.7427667234054045),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (11, 0.7772433631512911),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (12, 0.74649621038151),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (13, 0.7705862182525137),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (14, 0.8284477168218028),\n",
      "\u001b[92mINFO \u001b[0m:      \t              (15, 0.7808698294316616)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "client = ClientApp(client_fn=client_fn_binary)\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc406556-ae1a-48f8-bb65-fd4b7dc1cf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9f174fe-b90e-4a4b-bcd6-97c4e750658a",
   "metadata": {},
   "source": [
    "#### Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a9b7c-1728-4d14-8fb9-410a3fc81627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa8524c-f681-4a03-92f4-c5895a0819d8",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
